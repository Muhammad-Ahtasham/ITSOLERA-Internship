{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4uGYb6GOoCU1"
      },
      "outputs": [],
      "source": [
        "# !pip install tensorflow numpy matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = datasets.mnist.load_data()\n",
        "\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "x_train = np.expand_dims(x_train, axis=-1)\n",
        "x_test = np.expand_dims(x_test, axis=-1)\n",
        "\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skoLCQoXoHZV",
        "outputId": "923a100b-1e18-4487-aad6-59c325714e32"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "model = create_model()\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxvZfumCoKjH",
        "outputId": "d790d302-2e33-40a4-d492-cc9d709ea533"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 13, 13, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 5, 5, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1600)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                102464    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 121930 (476.29 KB)\n",
            "Trainable params: 121930 (476.29 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_adversarial_example(model, x, y, epsilon=0.1):\n",
        "    x = tf.convert_to_tensor(x)\n",
        "    y = tf.convert_to_tensor(y)\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(x)\n",
        "        prediction = model(x)\n",
        "        loss = tf.keras.losses.categorical_crossentropy(y, prediction)\n",
        "\n",
        "    gradient = tape.gradient(loss, x)\n",
        "\n",
        "    signed_grad = tf.sign(gradient)\n",
        "\n",
        "    adversarial_example = x + epsilon * signed_grad\n",
        "    adversarial_example = tf.clip_by_value(adversarial_example, 0, 1)\n",
        "\n",
        "    return adversarial_example\n"
      ],
      "metadata": {
        "id": "Jvil9PGqoM0i"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adv_model = create_model()\n",
        "batch_size = 64\n",
        "epochs = 5\n",
        "epsilon = 0.1\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f'Epoch {epoch+1}/{epochs}')\n",
        "\n",
        "    for i in range(0, len(x_train), batch_size):\n",
        "        x_batch = x_train[i:i+batch_size]\n",
        "        y_batch = y_train[i:i+batch_size]\n",
        "\n",
        "        x_adv_batch = generate_adversarial_example(adv_model, x_batch, y_batch, epsilon)\n",
        "\n",
        "        x_combined = np.concatenate([x_batch, x_adv_batch])\n",
        "        y_combined = np.concatenate([y_batch, y_batch])\n",
        "\n",
        "        adv_model.train_on_batch(x_combined, y_combined)\n",
        "\n",
        "    test_loss, test_acc = adv_model.evaluate(x_test, y_test, verbose=2)\n",
        "    print(f'Test accuracy after adversarial training: {test_acc:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEBrgMzQoOhh",
        "outputId": "275e1c39-dccd-4ea2-e2ec-e0ec5fa665ec"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "313/313 - 1s - loss: 0.0726 - accuracy: 0.9780 - 1s/epoch - 3ms/step\n",
            "Test accuracy after adversarial training: 0.9780\n",
            "Epoch 2/5\n",
            "313/313 - 1s - loss: 0.0481 - accuracy: 0.9843 - 890ms/epoch - 3ms/step\n",
            "Test accuracy after adversarial training: 0.9843\n",
            "Epoch 3/5\n",
            "313/313 - 1s - loss: 0.0368 - accuracy: 0.9879 - 899ms/epoch - 3ms/step\n",
            "Test accuracy after adversarial training: 0.9879\n",
            "Epoch 4/5\n",
            "313/313 - 1s - loss: 0.0310 - accuracy: 0.9896 - 868ms/epoch - 3ms/step\n",
            "Test accuracy after adversarial training: 0.9896\n",
            "Epoch 5/5\n",
            "313/313 - 1s - loss: 0.0289 - accuracy: 0.9900 - 875ms/epoch - 3ms/step\n",
            "Test accuracy after adversarial training: 0.9900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_adversarial_input(model, x, threshold=0.6):\n",
        "    predictions = model.predict(x)\n",
        "    confidence = np.max(predictions, axis=1)\n",
        "\n",
        "    adversarial_detected = confidence < threshold\n",
        "    return adversarial_detected\n"
      ],
      "metadata": {
        "id": "tXzwJtiRoSoN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_detection = detect_adversarial_input(model, x_test[:100])\n",
        "print(f\"Adversarial detected in clean data: {np.sum(clean_detection)}\")\n",
        "\n",
        "x_adv_test = generate_adversarial_example(adv_model, x_test[:100], y_test[:100], epsilon)\n",
        "\n",
        "adv_detection = detect_adversarial_input(adv_model, x_adv_test)\n",
        "print(f\"Adversarial detected in adversarial data: {np.sum(adv_detection)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1vhLfGvoWuU",
        "outputId": "46d4a34b-7acc-4d6b-943c-ead19ad2e01e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 3ms/step\n",
            "Adversarial detected in clean data: 100\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "Adversarial detected in adversarial data: 1\n"
          ]
        }
      ]
    }
  ]
}